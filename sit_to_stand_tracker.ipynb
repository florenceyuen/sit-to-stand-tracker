{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/florenceyuen/sit-to-stand-tracker/blob/main/sit_to_stand_tracker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8cDtxLIBHgQ"
      },
      "outputs": [],
      "source": [
        "# Check gpu connections\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjpPg4mGKc1v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdSMcABDNKW-"
      },
      "outputs": [],
      "source": [
        "# Yolo and dependency installations\n",
        "!pip install numpy==1.24.3 --quiet\n",
        "\n",
        "!pip install ultralytics==8.2.103 -q\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOEYrlBoP9-E"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx9NWF-sVN6Y"
      },
      "outputs": [],
      "source": [
        "model = YOLO(f'{HOME}/yolov8s-seg.pt')\n",
        "#results = model.predict(source='https://media.roboflow.com/notebooks/examples/dog.jpeg', conf=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<video id=\"video\" autoplay playsinline style=\"display:none;\"></video>\n",
        "<canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
        "<script>\n",
        "(async () => {\n",
        "  const video  = document.getElementById('video');\n",
        "  const canvas = document.getElementById('canvas');\n",
        "  const ctx    = canvas.getContext('2d');\n",
        "\n",
        "  try {\n",
        "    const stream = await navigator.mediaDevices.getUserMedia({video:true});\n",
        "    video.srcObject = stream;\n",
        "    await video.play();\n",
        "  } catch (e) {\n",
        "    console.error('Camera access denied or not available', e);\n",
        "    return;\n",
        "  }\n",
        "\n",
        "  canvas.width  = video.videoWidth;\n",
        "  canvas.height = video.videoHeight;\n",
        "  google.colab.output.setIframeHeight(canvas.height + 20);\n",
        "\n",
        "  window.captureFrame = () => {\n",
        "    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "    return canvas.toDataURL('image/jpeg', 0.8);\n",
        "  };\n",
        "</script>\n"
      ],
      "metadata": {
        "id": "3h8h8xKnMMRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding yolo pose models\n",
        "from ultralytics import YOLO\n",
        "pose_model = YOLO(\"yolov8n-pose.pt\")  # or yolov8m-pose.pt for better accuracy\n",
        "# pose_model = YOLO('yolov8m-pose.pt')\n"
      ],
      "metadata": {
        "id": "ba5y1ZlG-pgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "Bde1yixCmU3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import cycle\n",
        "\"\"\"\n",
        "Monitors and evaluates sit-to-stand movements, commonly used to\n",
        "assess lower-body strength and mobility, particularly in older adults. The application\n",
        "should track key joint angles or movement patterns to detect transitions and provide\n",
        "feedback on performance quality\n",
        "\n",
        "Author: Florence Yuen\n",
        "\"\"\"\n",
        "\n",
        "# ─── One‑Cell Live Pose + Sit-stand-tracker (fixed keypoint extraction for hip, knee angles) ───\n",
        "from IPython.display import Javascript, display\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2, numpy as np, time\n",
        "import ipywidgets as widgets\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "\n",
        "# Global variables for timing\n",
        "cycle_start_time = None\n",
        "rep_durations = []\n",
        "\n",
        "# 1) Inject JS for webcam + captureFrame()\n",
        "display(Javascript(\"\"\"\n",
        "(async () => {\n",
        "  const v = document.createElement('video');\n",
        "  v.autoplay = v.playsInline = true;\n",
        "  v.style.display = 'none';\n",
        "  document.body.appendChild(v);\n",
        "\n",
        "  const c = document.createElement('canvas');\n",
        "  c.style.display = 'none';\n",
        "  document.body.appendChild(c);\n",
        "  const ctx = c.getContext('2d');\n",
        "\n",
        "  const stream = await navigator.mediaDevices.getUserMedia({video:true});\n",
        "  v.srcObject = stream;\n",
        "  await v.play();\n",
        "\n",
        "  c.width = v.videoWidth; c.height = v.videoHeight;\n",
        "  google.colab.output.setIframeHeight(c.height + 20);\n",
        "\n",
        "  window.captureFrame = () => {\n",
        "    ctx.drawImage(v, 0, 0, c.width, c.height);\n",
        "    return c.toDataURL('image/jpeg', 0.8);\n",
        "  };\n",
        "})();\n",
        "\"\"\"))\n",
        "\n",
        "# 2) Wait for the JS function to be ready\n",
        "print(\"⏳ Initializing camera…\")\n",
        "for _ in range(25):\n",
        "    try:\n",
        "        if eval_js(\"typeof captureFrame\") == 'function':\n",
        "            print(\"✅ Camera ready!\")\n",
        "            break\n",
        "    except Exception:\n",
        "        pass\n",
        "    time.sleep(0.2)\n",
        "else:\n",
        "    raise RuntimeError(\"Camera never initialized—did you allow access?\")\n",
        "\n",
        "# 3) Helpers to grab frames and compute angles\n",
        "def get_frame():\n",
        "    data = eval_js('captureFrame()')\n",
        "    _, b64 = data.split(',', 1)\n",
        "    arr = np.frombuffer(b64decode(b64), dtype=np.uint8)\n",
        "    return cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
        "\n",
        "def angle_at_joint(kps, si, ei, wi):\n",
        "    S, E, W = kps[si, :2], kps[ei, :2], kps[wi, :2]\n",
        "    v1, v2 = S - E, W - E\n",
        "    cosang = np.dot(v1, v2) / (np.linalg.norm(v1)*np.linalg.norm(v2) + 1e-6)\n",
        "    return np.degrees(np.arccos(np.clip(cosang, -1, 1)))\n",
        "\n",
        "def angle_visualization(vis, kps, landmark, angle):\n",
        "    \"\"\"\n",
        "    Overlay angles onto the image visualization at the specified landmark\n",
        "\n",
        "    - vis: image (numpy array) to draw on\n",
        "    - kps: keypoints numpy array (shape [17,3])\n",
        "    - landmark: int, index of the keypoint to annotate\n",
        "    - angle: float, the angle value to display\n",
        "    \"\"\"\n",
        "    pt_joint = tuple(kps[landmark, :2].astype(int))\n",
        "    cv2.putText(vis, f\"{int(angle)}°\", (pt_joint[0] - 20, pt_joint[1]),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "def transition_detection(hip_angle, knee_angle, prev_posture):\n",
        "  STANDING_THRESHOLD = 140 # standing threshold: hip, knee angle > 140 deg\n",
        "  SITTING_THRESHOLD = 40 # sitting threshold: hip, knee angle < 100 deg\n",
        "\n",
        "  SITTING_THRESHOLD_HIP = 30\n",
        "  SITTING_THRESHOLD_KNEE = 140\n",
        "\n",
        "  STANDING_THRESHOLD_HIP = 20\n",
        "  STANDING_THRESHOLD_KNEE = 160\n",
        "\n",
        "  # Detect when posture transitions from sitting to standing, or standing to sitting\n",
        "  if (hip_angle < STANDING_THRESHOLD_HIP) and (knee_angle > STANDING_THRESHOLD_KNEE):\n",
        "    posture = \"standing\"\n",
        "  elif (hip_angle < SITTING_THRESHOLD_HIP) and (knee_angle < SITTING_THRESHOLD_KNEE):\n",
        "      posture = \"sitting\"\n",
        "  else: # in between state\n",
        "    posture = prev_posture\n",
        "  return posture\n",
        "\n",
        "# Symmetry Index: |L-R|/((L+R)/2) *100%, good symmetry is <10%\n",
        "def eval_symmetry(left, right):\n",
        "  imbalance = abs(left-right)\n",
        "  symmetry = (imbalance/((left+right)/2))*100\n",
        "  return symmetry\n",
        "\n",
        "def calc_ROM(hip_angles_left, hip_angles_right, knee_angles_left, knee_angles_right):\n",
        "  \"\"\" Range of motion (ROM) during transitions\"\"\"\n",
        "  rom_hip_left = max(hip_angles_left) - min(hip_angles_left)\n",
        "  rom_hip_right = max(hip_angles_right) - min(hip_angles_right)\n",
        "  rom_knee_left = max(knee_angles_left) - min(knee_angles_left)\n",
        "  rom_knee_right = max(knee_angles_right) - min(knee_angles_right)\n",
        "\n",
        "  return rom_hip_left, rom_hip_right, rom_knee_left, rom_knee_right\n",
        "\n",
        "def calc_cycle_time(cycle_start_time):\n",
        "  if cycle_start_time:\n",
        "      rep_duration = time.time() - cycle_start_time\n",
        "      rep_durations.append(rep_duration)\n",
        "      print(f\"Cycle completed in {rep_duration:.2f} seconds\")\n",
        "\n",
        "def track_cycles(hip_angle, knee_angle, prev_posture, num_reps, cycle_start_time):\n",
        "  \"\"\" Count number of cycles completed, track cycle timing \"\"\"\n",
        "  current_posture = transition_detection(hip_angle, knee_angle, prev_posture)\n",
        "\n",
        "  cycle_completed = False\n",
        "  rep_duration = None\n",
        "\n",
        "  if prev_posture == 'sitting' and current_posture == 'standing': # user begins standing\n",
        "    cycle_start_time = time.time()  # Cycle started, start timing\n",
        "    print(\"Changed to standing\")\n",
        "  # Check if completed one sit-to-stand-to-sit cycle\n",
        "  elif prev_posture == 'standing' and current_posture == 'sitting':\n",
        "    num_reps += 1\n",
        "    cycle_completed = True\n",
        "\n",
        "    # Claculate total cycle duration and reset for next cycle\n",
        "    calc_cycle_time(cycle_start_time)\n",
        "    cycle_start_time = None\n",
        "\n",
        "  return current_posture, num_reps, cycle_completed, cycle_start_time, rep_duration\n",
        "\n",
        "def compute_velocity(angle_list, fps=30):\n",
        "    velocities = []\n",
        "    for i in range(1, len(angle_list)):\n",
        "        vel = (angle_list[i] - angle_list[i-1]) * fps  # degrees per second approx.\n",
        "        velocities.append(vel)\n",
        "    return velocities\n",
        "\n",
        "def compute_smoothness(velocities):\n",
        "    # Lower std dev means smoother movement\n",
        "    return np.std(velocities)\n",
        "\n",
        "# 4) Load YOLOv8‑Pose model\n",
        "pose_model = YOLO(\"yolov8n-pose.pt\")  # or your custom pose weights\n",
        "\n",
        "# 5) Create a persistent widget for display\n",
        "img_wid = widgets.Image(format='jpeg')\n",
        "display(img_wid)\n",
        "\n",
        "# 6) Live loop: predict, draw skeleton, compute & overlay sitting and standing angles\n",
        "print(\"▶️ Live pose + sit-stand-tracker—Interrupt (⏹) to stop.\")\n",
        "\n",
        "# track number of repetitions (sit-->stand-->sit)\n",
        "hip_angles_left, hip_angles_right = [], []\n",
        "knee_angles_left, knee_angles_right = [], []\n",
        "prev_posture = None\n",
        "num_reps = 0\n",
        "try:\n",
        "    while True:\n",
        "        frame = get_frame()\n",
        "        res   = pose_model.predict(frame, stream=False)[0]\n",
        "        vis   = res.plot()\n",
        "\n",
        "        # **Fix**: extract the raw tensor from Coordinates, then to numpy\n",
        "        kps_arr = res.keypoints.data.detach().cpu().numpy()  # shape (n_people, 17, 3)\n",
        "\n",
        "        if kps_arr.shape[0] == 0:\n",
        "          continue  # skip frame if no people are detected\n",
        "\n",
        "        for kps in kps_arr:\n",
        "            # Filter low-confidence\n",
        "            if kps.shape[0] < 17: # skip incomplete detections for keypoints shape\n",
        "                continue  # skip incomplete detections\n",
        "\n",
        "            # Skip low-confidence keypoints by checking visibility/ confidence for hip, knee, ankle points\n",
        "            confidence_threshold = 0.3\n",
        "            required_indices = [5, 6, 11, 12, 13, 14, 15, 16 ]  # hips, knees, ankles, elbows: # , 7, 8\n",
        "            if any(kps[i, 2] < confidence_threshold for i in required_indices):\n",
        "                continue\n",
        "\n",
        "            # angles for left and right knee movement\n",
        "            kL = angle_at_joint(kps, 11, 13, 15)\n",
        "            kR = angle_at_joint(kps, 12, 14, 16)\n",
        "\n",
        "            # angles for left and right hip movement (shoulder, hip, knee)\n",
        "            hip_left = angle_at_joint(kps, 11, 5, 13)\n",
        "            hip_right = angle_at_joint(kps, 12, 6, 14)\n",
        "\n",
        "            print(\"Angle:\", hip_left, hip_right, kL, kR)\n",
        "\n",
        "            # Elbow: left = [5→7→9], right = [6→8→10]\n",
        "            # aL = angle_at_joint(kps, 5, 7, 9)\n",
        "            # aR = angle_at_joint(kps, 6, 8, 10\n",
        "\n",
        "            # Add angles for calculating range of motion\n",
        "            hip_angles_left.append(hip_left)\n",
        "            hip_angles_right.append(hip_right)\n",
        "            knee_angles_left.append(kL)\n",
        "            knee_angles_right.append(kR)\n",
        "\n",
        "            # Determine posture and sit-stand transitions\n",
        "            avg_hip = (hip_left + hip_right)/2\n",
        "            avg_knee = (kL + kR)/2\n",
        "\n",
        "            hip_avg = (hip_left + hip_right) / 2\n",
        "            knee_avg = (kL + kR) / 2\n",
        "\n",
        "            print(f\"Hip avg: {hip_avg:.1f}, Knee avg: {knee_avg:.1f} => Posture: {prev_posture}\")\n",
        "\n",
        "            # Determine current posture and update rep count using your function\n",
        "            prev_posture, num_reps, cycle_completed, cycle_start_time, rep_duration = track_cycles(hip_avg, knee_avg, prev_posture, num_reps, cycle_start_time)\n",
        "\n",
        "            if cycle_completed:\n",
        "              # Calculate ROM and symmetry\n",
        "              rom_hip_L, rom_hip_R, rom_knee_L, rom_knee_R = calc_ROM(hip_angles_left, hip_angles_right, knee_angles_left, knee_angles_right)\n",
        "\n",
        "              sym_hip = eval_symmetry(rom_hip_L, rom_hip_R)\n",
        "              sym_knee = eval_symmetry(rom_knee_L, rom_knee_R)\n",
        "\n",
        "              track_cycles(hip_left, kL, prev_posture, num_reps, cycle_start_time)\n",
        "              track_cycles(hip_right, kR, prev_posture, num_reps, cycle_start_time)\n",
        "\n",
        "              angle_lists = [hip_angles_left, hip_angles_right, knee_angles_left, knee_angles_right]\n",
        "              smoothness_results = []\n",
        "\n",
        "              for angles in angle_lists:\n",
        "                  # Calculate smoothness using velocity for each angle\n",
        "                  velocities = compute_velocity(angles)\n",
        "                  smoothness = compute_smoothness(velocities)\n",
        "                  smoothness_results.append(smoothness)\n",
        "\n",
        "                  # Clear angle lists for next cycle rep\n",
        "                  angles.clear()\n",
        "\n",
        "              smooth_hip_L, smooth_hip_R, smooth_knee_L, smooth_knee_R = smoothness_resultss\n",
        "\n",
        "              # Visualization and overlay of info for number of reps, symmetry, smoothness\n",
        "              cv2.putText(vis, f\"Reps: {num_reps}\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n",
        "              cv2.putText(vis, f\"Hip Sym: {sym_hip:.1f}%\", (10,70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0) if sym_hip < 10 else (0,0,255), 2)\n",
        "              cv2.putText(vis, f\"Knee Sym: {sym_knee:.1f}%\", (10,100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0) if sym_knee < 10 else (0,0,255), 2)\n",
        "\n",
        "              cv2.putText(vis, f\"Rep Time: {rep_duration:.2f}s\" if rep_duration else \"Rep Time: --\", (10,130), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
        "              cv2.putText(vis, f\"Hip L Smoothness: {smooth_hip_L:.1f}\", (10,160), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
        "              cv2.putText(vis, f\"Hip R Smoothness: {smooth_hip_R:.1f}\", (10,160), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
        "              cv2.putText(vis, f\"Knee R Smoothness: {smooth_knee_L:.1f}\", (10,160), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
        "              cv2.putText(vis, f\"Knee Smoothness: {smooth_knee_L:.1f}\", (10,160), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
        "\n",
        "            # Landmark index and corresponding angle value for visualization\n",
        "              landmarks_angles = [\n",
        "                  (13, kL),          # left knee angle\n",
        "                  (14, kR),          # right knee angle\n",
        "                  (5, hip_left),     # left hip angle\n",
        "                  (6, hip_right)     # right hip angle\n",
        "                  # (7, aL),           # left elbow angle\n",
        "                  # (8, aR)            # right elbow angle\n",
        "              ]\n",
        "\n",
        "              for landmark, angle in landmarks_angles:\n",
        "                  angle_visualization(vis, kps, landmark, angle)\n",
        "\n",
        "        _, jpg = cv2.imencode('.jpg', vis)\n",
        "        img_wid.value = jpg.tobytes()\n",
        "        time.sleep(0.03)  # tune this for latency vs. CPU/GPU load\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"⏹ Segmentation stopped.\")\n"
      ],
      "metadata": {
        "id": "ZjVBiK0z-3Dh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}