{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/florenceyuen/sit-to-stand-tracker/blob/main/sit_to_stand_tracker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cDtxLIBHgQ",
        "outputId": "ac13978c-7b8e-48fe-ce5a-2da270aaefaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun  4 22:01:59 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check gpu connections\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "db88754a-1e17-4c09-ae57-6eedd8cf8d7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "afa4217e-f60c-4e0b-f9f6-503371e2ad5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.103 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 41.7/112.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Yolo and dependency installations\n",
        "!pip install numpy==1.24.3 --quiet\n",
        "\n",
        "!pip install ultralytics==8.2.103 -q\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOEYrlBoP9-E"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx9NWF-sVN6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb31bda7-fa69-43cc-e745-0c8f86ef39f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-seg.pt to '/content/yolov8s-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22.8M/22.8M [00:00<00:00, 398MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(f'{HOME}/yolov8s-seg.pt')\n",
        "#results = model.predict(source='https://media.roboflow.com/notebooks/examples/dog.jpeg', conf=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<video id=\"video\" autoplay playsinline style=\"display:none;\"></video>\n",
        "<canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
        "<script>\n",
        "(async () => {\n",
        "  const video  = document.getElementById('video');\n",
        "  const canvas = document.getElementById('canvas');\n",
        "  const ctx    = canvas.getContext('2d');\n",
        "\n",
        "  try {\n",
        "    const stream = await navigator.mediaDevices.getUserMedia({video:true});\n",
        "    video.srcObject = stream;\n",
        "    await video.play();\n",
        "  } catch (e) {\n",
        "    console.error('Camera access denied or not available', e);\n",
        "    return;\n",
        "  }\n",
        "\n",
        "  canvas.width  = video.videoWidth;\n",
        "  canvas.height = video.videoHeight;\n",
        "  google.colab.output.setIframeHeight(canvas.height + 20);\n",
        "\n",
        "  window.captureFrame = () => {\n",
        "    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "    return canvas.toDataURL('image/jpeg', 0.8);\n",
        "  };\n",
        "</script>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3h8h8xKnMMRw",
        "outputId": "37181613-0eee-4830-bf97-bdc47b0b31b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video id=\"video\" autoplay playsinline style=\"display:none;\"></video>\n",
              "<canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "<script>\n",
              "(async () => {\n",
              "  const video  = document.getElementById('video');\n",
              "  const canvas = document.getElementById('canvas');\n",
              "  const ctx    = canvas.getContext('2d');\n",
              "\n",
              "  try {\n",
              "    const stream = await navigator.mediaDevices.getUserMedia({video:true});\n",
              "    video.srcObject = stream;\n",
              "    await video.play();\n",
              "  } catch (e) {\n",
              "    console.error('Camera access denied or not available', e);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  canvas.width  = video.videoWidth;\n",
              "  canvas.height = video.videoHeight;\n",
              "  google.colab.output.setIframeHeight(canvas.height + 20);\n",
              "\n",
              "  window.captureFrame = () => {\n",
              "    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
              "    return canvas.toDataURL('image/jpeg', 0.8);\n",
              "  };\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding yolo pose models\n",
        "from ultralytics import YOLO\n",
        "pose_model = YOLO(\"yolov8n-pose.pt\")  # or yolov8m-pose.pt for better accuracy\n",
        "# pose_model = YOLO('yolov8m-pose.pt')\n"
      ],
      "metadata": {
        "id": "ba5y1ZlG-pgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e36fa36-8749-42d1-c51c-0ecfdda7f12b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-pose.pt to 'yolov8n-pose.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.52M/6.52M [00:00<00:00, 183MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ultralytics YOLOv8-Pose follows the 17-keypoint “COCO” convention\n",
        "---\n",
        "\n",
        "## 1. How the angle calculation works\n",
        "\n",
        "1. **Gather the three 2-D points** that form the joint:  \n",
        "   * **S** (start / proximal …)  \n",
        "   * **E** (elbow – vertex)  \n",
        "   * **W** (end / distal …)\n",
        "\n",
        "2. **Form two limb-segment vectors** that share the vertex  \n",
        "\n",
        "$$\n",
        "\\vec{v_1} = \\mathbf{S} - \\mathbf{E},\\qquad\n",
        "\\vec{v_2} = \\mathbf{W} - \\mathbf{E}\n",
        "$$\n",
        "\n",
        "\n",
        "3. **Compute the cosine**  \n",
        "\n",
        "$$\n",
        "\\cos\\theta = \\frac{\\,\\vec{v_1}\\cdot\\vec{v_2}\\,}\n",
        "                 {\\lVert\\vec{v_1}\\rVert\\,\\lVert\\vec{v_2}\\rVert}\n",
        "$$\n",
        "\n",
        "\n",
        "4. **Convert to degrees**  \n",
        "\n",
        "\n",
        "$$\n",
        "\\theta = \\arccos(\\cos\\theta)\\times\\frac{180}{\\pi}\n",
        "$$\n",
        "\n",
        "The tiny `1e-6` in the denominator of `angle_at_joint()` avoids division-by-zero.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. YOLOv8 / COCO 17-keypoint index map\n",
        "\n",
        "| Index | Landmark | Typical use-case | Notes |\n",
        "|-----:|-----------|------------------|-------|\n",
        "| 0 | Nose | Head orientation | Center of face |\n",
        "| 1 | Left Eye | Gaze / blink | |\n",
        "| 2 | Right Eye | | |\n",
        "| 3 | Left Ear | Head yaw | |\n",
        "| 4 | Right Ear | | |\n",
        "| **5** | **Left Shoulder** | Upper-arm root | Start of **left elbow angle** |\n",
        "| **6** | **Right Shoulder** | | Start of **right elbow angle** |\n",
        "| **7** | **Left Elbow** | Elbow flexion | Vertex |\n",
        "| **8** | **Right Elbow** | | Vertex |\n",
        "| 9 | Left Wrist | Wrist pose / elbow | |\n",
        "| 10 | Right Wrist | | |\n",
        "| 11 | Left Hip | Trunk inclination | |\n",
        "| 12 | Right Hip | | |\n",
        "| 13 | Left Knee | Knee flexion | |\n",
        "| 14 | Right Knee | | |\n",
        "| 15 | Left Ankle | Gait analysis | |\n",
        "| 16 | Right Ankle | | |\n",
        "\n",
        "### Example – elbow flexion  \n",
        "* **Left:** `[5 → 7 → 9]` (shoulder–elbow–wrist)  \n",
        "* **Right:** `[6 → 8 → 10]`\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Confidence filtering & best practices\n",
        "\n",
        "* **Keypoint confidence**: use the 3ʳᵈ value in each keypoint row (0–1) to skip uncertain detections.  \n",
        "* **Units**: coordinates are pixels; angles are unit-free, but segment *lengths* need scaling.  \n",
        "* **2-D vs 3-D**: for true joint angles in space, capture depth or multi-view 3-D first.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Further documentation & resources\n",
        "\n",
        "* **Ultralytics Pose guide** – quick-start, skeleton diagram.  \n",
        "https://docs.ultralytics.com/tasks/pose/#models\n",
        "\n",
        "https://github.com/Alimustoofaa/YoloV8-Pose-Keypoint-Classification\n"
      ],
      "metadata": {
        "id": "IhRsk6ruN57J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "Bde1yixCmU3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import cycle\n",
        "\"\"\"\n",
        "Monitors and evaluates sit-to-stand movements, commonly used to\n",
        "assess lower-body strength and mobility, particularly in older adults. The application\n",
        "should track key joint angles or movement patterns to detect transitions and provide\n",
        "feedback on performance quality\n",
        "\"\"\"\n",
        "\n",
        "# ─── One‑Cell Live Pose + Elbow‑Angle Estimation (fixed keypoint extraction) ───\n",
        "from IPython.display import Javascript, display\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2, numpy as np, time\n",
        "import ipywidgets as widgets\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "\n",
        "# Global variables for timing\n",
        "cycle_start_time = None\n",
        "rep_durations = []\n",
        "\n",
        "# 1) Inject JS for webcam + captureFrame()\n",
        "display(Javascript(\"\"\"\n",
        "(async () => {\n",
        "  const v = document.createElement('video');\n",
        "  v.autoplay = v.playsInline = true;\n",
        "  v.style.display = 'none';\n",
        "  document.body.appendChild(v);\n",
        "\n",
        "  const c = document.createElement('canvas');\n",
        "  c.style.display = 'none';\n",
        "  document.body.appendChild(c);\n",
        "  const ctx = c.getContext('2d');\n",
        "\n",
        "  const stream = await navigator.mediaDevices.getUserMedia({video:true});\n",
        "  v.srcObject = stream;\n",
        "  await v.play();\n",
        "\n",
        "  c.width = v.videoWidth; c.height = v.videoHeight;\n",
        "  google.colab.output.setIframeHeight(c.height + 20);\n",
        "\n",
        "  window.captureFrame = () => {\n",
        "    ctx.drawImage(v, 0, 0, c.width, c.height);\n",
        "    return c.toDataURL('image/jpeg', 0.8);\n",
        "  };\n",
        "})();\n",
        "\"\"\"))\n",
        "\n",
        "# 2) Wait for the JS function to be ready\n",
        "print(\"⏳ Initializing camera…\")\n",
        "for _ in range(25):\n",
        "    try:\n",
        "        if eval_js(\"typeof captureFrame\") == 'function':\n",
        "            print(\"✅ Camera ready!\")\n",
        "            break\n",
        "    except Exception:\n",
        "        pass\n",
        "    time.sleep(0.2)\n",
        "else:\n",
        "    raise RuntimeError(\"Camera never initialized—did you allow access?\")\n",
        "\n",
        "# 3) Helpers to grab frames and compute angles\n",
        "def get_frame():\n",
        "    data = eval_js('captureFrame()')\n",
        "    _, b64 = data.split(',', 1)\n",
        "    arr = np.frombuffer(b64decode(b64), dtype=np.uint8)\n",
        "    return cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
        "\n",
        "def angle_at_joint(kps, si, ei, wi):\n",
        "    S, E, W = kps[si, :2], kps[ei, :2], kps[wi, :2]\n",
        "    v1, v2 = S - E, W - E\n",
        "    cosang = np.dot(v1, v2) / (np.linalg.norm(v1)*np.linalg.norm(v2) + 1e-6)\n",
        "    return np.degrees(np.arccos(np.clip(cosang, -1, 1)))\n",
        "\n",
        "def angle_visualization(vis, kps, landmark, angle):\n",
        "    \"\"\"\n",
        "    Overlay angles onto the image visualization at the specified landmark\n",
        "\n",
        "    - vis: image (numpy array) to draw on\n",
        "    - kps: keypoints numpy array (shape [17,3])\n",
        "    - landmark: int, index of the keypoint to annotate\n",
        "    - angle: float, the angle value to display\n",
        "    \"\"\"\n",
        "    pt_joint = tuple(kps[landmark, :2].astype(int))\n",
        "    cv2.putText(vis, f\"{int(angle)}°\", (pt_joint[0] - 20, pt_joint[1]),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "def transition_detection(hip_angle, knee_angle, prev_posture):\n",
        "  STANDING_THRESHOLD = 140 # standing threshold: hip, knee angle > 140 deg\n",
        "  SITTING_THRESHOLD = 40 # sitting threshold: hip, knee angle < 100 deg\n",
        "\n",
        "  SITTING_THRESHOLD_HIP = 30\n",
        "  SITTING_THRESHOLD_KNEE = 140\n",
        "\n",
        "  STANDING_THRESHOLD_HIP = 20\n",
        "  STANDING_THRESHOLD_KNEE = 160\n",
        "\n",
        "  # Detect when posture transitions from sitting to standing, or standing to sitting\n",
        "  if (hip_angle < STANDING_THRESHOLD_HIP) and (knee_angle > STANDING_THRESHOLD_KNEE):\n",
        "    posture = \"standing\"\n",
        "  elif (hip_angle < SITTING_THRESHOLD_HIP) and (knee_angle < SITTING_THRESHOLD_KNEE):\n",
        "      posture = \"sitting\"\n",
        "  else: # in between state\n",
        "    posture = prev_posture\n",
        "  return posture\n",
        "\n",
        "# Symmetry Index: |L-R|/((L+R)/2) *100%, good symmetry is <10%\n",
        "def eval_symmetry(left, right):\n",
        "  imbalance = abs(left-right)\n",
        "  symmetry = (imbalance/((left+right)/2))*100\n",
        "  return symmetry\n",
        "\n",
        "def calc_ROM(hip_angles_left, hip_angles_right, knee_angles_left, knee_angles_right):\n",
        "  \"\"\" Range of motion (ROM) during transitions\"\"\"\n",
        "  rom_hip_left = max(hip_angles_left) - min(hip_angles_left)\n",
        "  rom_hip_right = max(hip_angles_right) - min(hip_angles_right)\n",
        "  rom_knee_left = max(knee_angles_left) - min(knee_angles_left)\n",
        "  rom_knee_right = max(knee_angles_right) - min(knee_angles_right)\n",
        "\n",
        "  return rom_hip_left, rom_hip_right, rom_knee_left, rom_knee_right\n",
        "\n",
        "def calc_cycle_time(cycle_start_time):\n",
        "  if cycle_start_time:\n",
        "      rep_duration = time.time() - cycle_start_time\n",
        "      rep_durations.append(rep_duration)\n",
        "      print(f\"Cycle completed in {rep_duration:.2f} seconds\")\n",
        "\n",
        "def track_cycles(hip_angle, knee_angle, prev_posture, num_reps, cycle_start_time):\n",
        "  \"\"\" Count number of cycles completed, track cycle timing \"\"\"\n",
        "  current_posture = transition_detection(hip_angle, knee_angle, prev_posture)\n",
        "\n",
        "  cycle_completed = False\n",
        "  rep_duration = None\n",
        "\n",
        "  if prev_posture == 'sitting' and current_posture == 'standing': # user begins standing\n",
        "    cycle_start_time = time.time()  # Cycle started, start timing\n",
        "    print(\"Changed to standing\")\n",
        "  # Check if completed one sit-to-stand-to-sit cycle\n",
        "  elif prev_posture == 'standing' and current_posture == 'sitting':\n",
        "    num_reps += 1\n",
        "    cycle_completed = True\n",
        "\n",
        "    # Claculate total cycle duration and reset for next cycle\n",
        "    calc_cycle_time(cycle_start_time)\n",
        "    cycle_start_time = None\n",
        "\n",
        "  return current_posture, num_reps, cycle_completed, cycle_start_time, rep_duration\n",
        "\n",
        "def compute_velocity(angle_list, fps=30):\n",
        "    velocities = []\n",
        "    for i in range(1, len(angle_list)):\n",
        "        vel = (angle_list[i] - angle_list[i-1]) * fps  # degrees per second approx.\n",
        "        velocities.append(vel)\n",
        "    return velocities\n",
        "\n",
        "def compute_smoothness(velocities):\n",
        "    # Lower std dev means smoother movement\n",
        "    return np.std(velocities)\n",
        "\n",
        "# 4) Load YOLOv8‑Pose model\n",
        "pose_model = YOLO(\"yolov8n-pose.pt\")  # or your custom pose weights\n",
        "\n",
        "# 5) Create a persistent widget for display\n",
        "img_wid = widgets.Image(format='jpeg')\n",
        "display(img_wid)\n",
        "\n",
        "# 6) Live loop: predict, draw skeleton, compute & overlay sitting and standing angles\n",
        "print(\"▶️ Live pose + sit-stand-tracker—Interrupt (⏹) to stop.\")\n",
        "\n",
        "# track number of repetitions (sit-->stand-->sit)\n",
        "hip_angles_left, hip_angles_right = [], []\n",
        "knee_angles_left, knee_angles_right = [], []\n",
        "prev_posture = None\n",
        "num_reps = 0\n",
        "try:\n",
        "    while True:\n",
        "        frame = get_frame()\n",
        "        res   = pose_model.predict(frame, stream=False)[0]\n",
        "        vis   = res.plot()\n",
        "\n",
        "        # **Fix**: extract the raw tensor from Coordinates, then to numpy\n",
        "        kps_arr = res.keypoints.data.detach().cpu().numpy()  # shape (n_people, 17, 3)\n",
        "\n",
        "        if kps_arr.shape[0] == 0:\n",
        "          continue  # skip frame if no people are detected\n",
        "\n",
        "        for kps in kps_arr:\n",
        "            # Filter low-confidence\n",
        "            if kps.shape[0] < 17: # skip incomplete detections for keypoints shape\n",
        "                continue  # skip incomplete detections\n",
        "\n",
        "            # Skip low-confidence keypoints by checking visibility/ confidence for hip, knee, ankle points\n",
        "            confidence_threshold = 0.3\n",
        "            required_indices = [5, 6, 11, 12, 13, 14, 15, 16 ]  # hips, knees, ankles, elbows: # , 7, 8\n",
        "            if any(kps[i, 2] < confidence_threshold for i in required_indices):\n",
        "                continue\n",
        "\n",
        "            # angles for left and right knee movement\n",
        "            kL = angle_at_joint(kps, 11, 13, 15)\n",
        "            kR = angle_at_joint(kps, 12, 14, 16)\n",
        "\n",
        "            # angles for left and right hip movement (shoulder, hip, knee)\n",
        "            hip_left = angle_at_joint(kps, 11, 5, 13)\n",
        "            hip_right = angle_at_joint(kps, 12, 6, 14)\n",
        "\n",
        "            print(\"Angle:\", hip_left, hip_right, kL, kR)\n",
        "\n",
        "            # Elbow: left = [5→7→9], right = [6→8→10]\n",
        "            # aL = angle_at_joint(kps, 5, 7, 9)\n",
        "            # aR = angle_at_joint(kps, 6, 8, 10\n",
        "\n",
        "            # Add angles for calculating range of motion\n",
        "            hip_angles_left.append(hip_left)\n",
        "            hip_angles_right.append(hip_right)\n",
        "            knee_angles_left.append(kL)\n",
        "            knee_angles_right.append(kR)\n",
        "\n",
        "            # Determine posture and sit-stand transitions\n",
        "            avg_hip = (hip_left + hip_right)/2\n",
        "            avg_knee = (kL + kR)/2\n",
        "\n",
        "            hip_avg = (hip_left + hip_right) / 2\n",
        "            knee_avg = (kL + kR) / 2\n",
        "\n",
        "            print(f\"Hip avg: {hip_avg:.1f}, Knee avg: {knee_avg:.1f} => Posture: {prev_posture}\")\n",
        "\n",
        "            # Determine current posture and update rep count using your function\n",
        "            prev_posture, num_reps, cycle_completed, cycle_start_time, rep_duration = track_cycles(hip_avg, knee_avg, prev_posture, num_reps, cycle_start_time)\n",
        "\n",
        "            if cycle_completed:\n",
        "              # Calculate ROM and symmetry\n",
        "              rom_hip_L, rom_hip_R, rom_knee_L, rom_knee_R = calc_ROM(hip_angles_left, hip_angles_right, knee_angles_left, knee_angles_right)\n",
        "\n",
        "              sym_hip = eval_symmetry(rom_hip_L, rom_hip_R)\n",
        "              sym_knee = eval_symmetry(rom_knee_L, rom_knee_R)\n",
        "\n",
        "              track_cycles(hip_left, kL, prev_posture, num_reps, cycle_start_time)\n",
        "              track_cycles(hip_right, kR, prev_posture, num_reps, cycle_start_time)\n",
        "\n",
        "              angle_lists = [hip_angles_left, hip_angles_right, knee_angles_left, knee_angles_right]\n",
        "              smoothness_results = []\n",
        "\n",
        "              for angles in angle_lists:\n",
        "                  # Calculate smoothness using velocity for each angle\n",
        "                  velocities = compute_velocity(angles)\n",
        "                  smoothness = compute_smoothness(velocities)\n",
        "                  smoothness_results.append(smoothness)\n",
        "\n",
        "                  # Clear angle lists for next cycle rep\n",
        "                  angles.clear()\n",
        "\n",
        "              smooth_hip_L, smooth_hip_R, smooth_knee_L, smooth_knee_R = smoothness_resultss\n",
        "\n",
        "              # Visualization and overlay of info for number of reps, symmetry, smoothness\n",
        "              cv2.putText(vis, f\"Reps: {num_reps}\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n",
        "              cv2.putText(vis, f\"Hip Sym: {sym_hip:.1f}%\", (10,70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0) if sym_hip < 10 else (0,0,255), 2)\n",
        "              cv2.putText(vis, f\"Knee Sym: {sym_knee:.1f}%\", (10,100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0) if sym_knee < 10 else (0,0,255), 2)\n",
        "\n",
        "              cv2.putText(vis, f\"Rep Time: {rep_duration:.2f}s\" if rep_duration else \"Rep Time: --\", (10,130), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
        "              cv2.putText(vis, f\"Hip L Smoothness: {smooth_hip_L:.1f}\", (10,160), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
        "              cv2.putText(vis, f\"Hip R Smoothness: {smooth_hip_R:.1f}\", (10,160), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
        "              cv2.putText(vis, f\"Knee R Smoothness: {smooth_knee_L:.1f}\", (10,160), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
        "              cv2.putText(vis, f\"Knee Smoothness: {smooth_knee_L:.1f}\", (10,160), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
        "\n",
        "            # Landmark index and corresponding angle value for visualization\n",
        "              landmarks_angles = [\n",
        "                  (13, kL),          # left knee angle\n",
        "                  (14, kR),          # right knee angle\n",
        "                  (5, hip_left),     # left hip angle\n",
        "                  (6, hip_right)     # right hip angle\n",
        "                  # (7, aL),           # left elbow angle\n",
        "                  # (8, aR)            # right elbow angle\n",
        "              ]\n",
        "\n",
        "              for landmark, angle in landmarks_angles:\n",
        "                  angle_visualization(vis, kps, landmark, angle)\n",
        "\n",
        "        _, jpg = cv2.imencode('.jpg', vis)\n",
        "        img_wid.value = jpg.tobytes()\n",
        "        time.sleep(0.03)  # tune this for latency vs. CPU/GPU load\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"⏹ Segmentation stopped.\")\n"
      ],
      "metadata": {
        "id": "ZjVBiK0z-3Dh",
        "outputId": "86cca45b-ebb8-4697-e94c-6559d3d526b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500,
          "referenced_widgets": [
            "aef5a1981996467c8baebbc771aa8a40",
            "87ea9e966d5549aaa050d7702fe355cb"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "(async () => {\n",
              "  const v = document.createElement('video');\n",
              "  v.autoplay = v.playsInline = true;\n",
              "  v.style.display = 'none';\n",
              "  document.body.appendChild(v);\n",
              "\n",
              "  const c = document.createElement('canvas');\n",
              "  c.style.display = 'none';\n",
              "  document.body.appendChild(c);\n",
              "  const ctx = c.getContext('2d');\n",
              "\n",
              "  const stream = await navigator.mediaDevices.getUserMedia({video:true});\n",
              "  v.srcObject = stream;\n",
              "  await v.play();\n",
              "\n",
              "  c.width = v.videoWidth; c.height = v.videoHeight;\n",
              "  google.colab.output.setIframeHeight(c.height + 20);\n",
              "\n",
              "  window.captureFrame = () => {\n",
              "    ctx.drawImage(v, 0, 0, c.width, c.height);\n",
              "    return c.toDataURL('image/jpeg', 0.8);\n",
              "  };\n",
              "})();\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Initializing camera…\n",
            "✅ Camera ready!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Image(value=b'', format='jpeg')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aef5a1981996467c8baebbc771aa8a40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ Live pose + sit-stand-tracker—Interrupt (⏹) to stop.\n",
            "\n",
            "0: 480x640 1 person, 11.0ms\n",
            "Speed: 1.4ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.1ms\n",
            "Speed: 1.7ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.5ms\n",
            "Speed: 1.5ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 12.9ms\n",
            "Speed: 1.5ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.7ms\n",
            "Speed: 1.6ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.0ms\n",
            "Speed: 1.7ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 15.1ms\n",
            "Speed: 1.6ms preprocess, 15.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.2ms\n",
            "Speed: 1.6ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.8ms\n",
            "Speed: 1.7ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.1ms\n",
            "Speed: 1.7ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.6ms\n",
            "Speed: 1.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.8ms\n",
            "Speed: 1.6ms preprocess, 10.8ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.5ms\n",
            "Speed: 1.5ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 15.5ms\n",
            "Speed: 1.7ms preprocess, 15.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.0ms\n",
            "Speed: 1.7ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 7.8ms\n",
            "Speed: 1.9ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.3ms\n",
            "Speed: 1.6ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 9.4ms\n",
            "Speed: 1.7ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.7ms\n",
            "Speed: 1.6ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 9.5ms\n",
            "Speed: 1.7ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 7.9ms\n",
            "Speed: 1.6ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.9ms\n",
            "Speed: 1.7ms preprocess, 13.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 0.21969413494816376 0.10048284473815591 41.08980788956749 55.61132258005421\n",
            "Hip avg: 0.2, Knee avg: 48.4 => Posture: None\n",
            "\n",
            "0: 480x640 1 person, 12.6ms\n",
            "Speed: 1.6ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 7.753352509018441 1.8106020653420591 176.79762659263716 177.22588805478048\n",
            "Hip avg: 4.8, Knee avg: 177.0 => Posture: sitting\n",
            "Changed to standing\n",
            "\n",
            "0: 480x640 1 person, 15.9ms\n",
            "Speed: 1.6ms preprocess, 15.9ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 2.4062387031397914 1.5016761377579224 164.8651176755367 165.6156719714491\n",
            "Hip avg: 2.0, Knee avg: 165.2 => Posture: standing\n",
            "\n",
            "0: 480x640 1 person, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 0.18585833494544604 5.691452217003246 155.81067165776594 159.22491341616106\n",
            "Hip avg: 2.9, Knee avg: 157.5 => Posture: standing\n",
            "\n",
            "0: 480x640 1 person, 9.3ms\n",
            "Speed: 1.6ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 4.204536812975961 6.50061348578303 171.85351950368252 172.95901589927945\n",
            "Hip avg: 5.4, Knee avg: 172.4 => Posture: standing\n",
            "\n",
            "0: 480x640 1 person, 12.1ms\n",
            "Speed: 1.7ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 14.09357566004408 19.982718941408756 144.49447149547444 138.8561426083254\n",
            "Hip avg: 17.0, Knee avg: 141.7 => Posture: standing\n",
            "\n",
            "0: 480x640 1 person, 12.9ms\n",
            "Speed: 1.6ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 21.640330537946003 27.492687510950695 119.48634188156697 115.1888536023409\n",
            "Hip avg: 24.6, Knee avg: 117.3 => Posture: standing\n",
            "Cycle completed in 2.34 seconds\n",
            "\n",
            "0: 480x640 1 person, 13.5ms\n",
            "Speed: 1.6ms preprocess, 13.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 17.408946569556576 21.351713273385048 121.10245105197377 118.97621817823013\n",
            "Hip avg: 19.4, Knee avg: 120.0 => Posture: sitting\n",
            "\n",
            "0: 480x640 1 person, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 18.304007151697125 25.933471831182224 117.69978558657158 113.9356332110272\n",
            "Hip avg: 22.1, Knee avg: 115.8 => Posture: sitting\n",
            "\n",
            "0: 480x640 1 person, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 19.103835289392073 25.874098576383357 118.5895233841446 115.57687761629381\n",
            "Hip avg: 22.5, Knee avg: 117.1 => Posture: sitting\n",
            "\n",
            "0: 480x640 1 person, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 22.773766590158054 26.55530531434133 127.34521558819303 126.6137820126862\n",
            "Hip avg: 24.7, Knee avg: 127.0 => Posture: sitting\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 6.074286975512612 7.813769514220373 156.67425712374472 157.90753446177075\n",
            "Hip avg: 6.9, Knee avg: 157.3 => Posture: sitting\n",
            "\n",
            "0: 480x640 1 person, 10.7ms\n",
            "Speed: 1.6ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 1.932995434993775 0.8583610863542196 172.01578476713905 177.68449773785608\n",
            "Hip avg: 1.4, Knee avg: 174.9 => Posture: sitting\n",
            "Changed to standing\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.6ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 2.070841692345564 0.7708548667016951 178.32895291638673 178.32583928242448\n",
            "Hip avg: 1.4, Knee avg: 178.3 => Posture: standing\n",
            "\n",
            "0: 480x640 1 person, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 1.0006908114165798 3.2714963655462275 179.5296297849913 177.4527580565556\n",
            "Hip avg: 2.1, Knee avg: 178.5 => Posture: standing\n",
            "\n",
            "0: 480x640 1 person, 11.3ms\n",
            "Speed: 1.6ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 0.0 2.7911504843665216 169.10120775391928 171.6386244996962\n",
            "Hip avg: 1.4, Knee avg: 170.4 => Posture: standing\n",
            "\n",
            "0: 480x640 1 person, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 8.190856009613237 3.9084179665215046 174.21289599678212 176.73689932107294\n",
            "Hip avg: 6.0, Knee avg: 175.5 => Posture: standing\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 9.935043018109166 5.5608722452585235 158.3030967045136 150.43495220639196\n",
            "Hip avg: 7.7, Knee avg: 154.4 => Posture: standing\n",
            "\n",
            "0: 480x640 1 person, 9.3ms\n",
            "Speed: 1.6ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 9.417471107894885 4.690509358085522 155.60408141462807 156.23226634945559\n",
            "Hip avg: 7.1, Knee avg: 155.9 => Posture: standing\n",
            "\n",
            "0: 480x640 1 person, 10.8ms\n",
            "Speed: 3.8ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 27.33855475865138 22.665127940638325 116.67606536777538 117.44585956340316\n",
            "Hip avg: 25.0, Knee avg: 117.1 => Posture: standing\n",
            "Cycle completed in 3.08 seconds\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 30.72147145535869 28.260394548113595 107.99614665213674 103.76221820524451\n",
            "Hip avg: 29.5, Knee avg: 105.9 => Posture: sitting\n",
            "\n",
            "0: 480x640 1 person, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 29.189846314872828 24.745359671027167 107.13148877876071 105.45716403029633\n",
            "Hip avg: 27.0, Knee avg: 106.3 => Posture: sitting\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 26.98825307232131 21.243004715838953 113.17435817209316 115.2130861849458\n",
            "Hip avg: 24.1, Knee avg: 114.2 => Posture: sitting\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 26.537688251470108 20.437729685831474 112.91134764941866 120.49043404512848\n",
            "Hip avg: 23.5, Knee avg: 116.7 => Posture: sitting\n",
            "\n",
            "0: 480x640 1 person, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 7.408375893975684 3.2199090729295627 158.0898984698961 166.65507477598237\n",
            "Hip avg: 5.3, Knee avg: 162.4 => Posture: sitting\n",
            "Changed to standing\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 3.2163346158144757 2.9152888118913367 171.13550551774927 177.97878835392066\n",
            "Hip avg: 3.1, Knee avg: 174.6 => Posture: standing\n",
            "\n",
            "0: 480x640 1 person, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 0.6333370837987552 3.8447383573253586 176.53836678940314 169.9428466131804\n",
            "Hip avg: 2.2, Knee avg: 173.2 => Posture: standing\n",
            "\n",
            "0: 480x640 1 person, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 1.8989980925331311 3.906681715266547 178.17591343804116 178.8665827466179\n",
            "Hip avg: 2.9, Knee avg: 178.5 => Posture: standing\n",
            "\n",
            "0: 480x640 1 person, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Angle: 2.0487257829315926 2.4644304086748634 45.015322075726644 38.33147604835545\n",
            "Hip avg: 2.3, Knee avg: 41.7 => Posture: standing\n",
            "Cycle completed in 1.72 seconds\n",
            "\n",
            "0: 480x640 1 person, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 12.0ms\n",
            "Speed: 1.6ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.6ms\n",
            "Speed: 1.5ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.3ms\n",
            "Speed: 1.7ms preprocess, 14.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.4ms\n",
            "Speed: 1.6ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.6ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.6ms\n",
            "Speed: 2.6ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.6ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.5ms\n",
            "Speed: 1.7ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.6ms\n",
            "Speed: 1.7ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.3ms\n",
            "Speed: 1.6ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.3ms\n",
            "Speed: 1.7ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.4ms\n",
            "Speed: 1.7ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 16.3ms\n",
            "Speed: 1.7ms preprocess, 16.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.0ms\n",
            "Speed: 1.7ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 16.4ms\n",
            "Speed: 1.7ms preprocess, 16.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.3ms\n",
            "Speed: 1.6ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 16.8ms\n",
            "Speed: 1.7ms preprocess, 16.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.6ms\n",
            "Speed: 1.6ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 15.7ms\n",
            "Speed: 1.6ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 15.7ms\n",
            "Speed: 1.6ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 17.1ms\n",
            "Speed: 1.7ms preprocess, 17.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.9ms\n",
            "Speed: 1.7ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.9ms\n",
            "Speed: 1.6ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.7ms\n",
            "Speed: 1.7ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.1ms\n",
            "Speed: 1.6ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.4ms\n",
            "Speed: 1.7ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.3ms\n",
            "Speed: 1.6ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 12.4ms\n",
            "Speed: 1.7ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 15.7ms\n",
            "Speed: 1.8ms preprocess, 15.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.5ms\n",
            "Speed: 1.6ms preprocess, 14.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.3ms\n",
            "Speed: 1.6ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 12.8ms\n",
            "Speed: 1.7ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 2.0ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.1ms\n",
            "Speed: 1.7ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.9ms\n",
            "Speed: 1.6ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.1ms\n",
            "Speed: 1.7ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.1ms\n",
            "Speed: 1.7ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 16.2ms\n",
            "Speed: 1.9ms preprocess, 16.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.6ms\n",
            "Speed: 1.6ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 17.7ms\n",
            "Speed: 1.6ms preprocess, 17.7ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 17.8ms\n",
            "Speed: 1.6ms preprocess, 17.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.6ms\n",
            "Speed: 1.6ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.7ms\n",
            "Speed: 1.7ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.0ms\n",
            "Speed: 1.6ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.9ms\n",
            "Speed: 1.7ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.5ms\n",
            "Speed: 1.6ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.0ms\n",
            "Speed: 1.6ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.0ms\n",
            "Speed: 2.1ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.3ms\n",
            "Speed: 1.6ms preprocess, 14.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.3ms\n",
            "Speed: 1.7ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 15.8ms\n",
            "Speed: 1.6ms preprocess, 15.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.6ms\n",
            "Speed: 1.7ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.6ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.6ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 12.6ms\n",
            "Speed: 1.6ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 15.5ms\n",
            "Speed: 1.6ms preprocess, 15.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.9ms\n",
            "Speed: 1.7ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.1ms\n",
            "Speed: 1.6ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 11.1ms\n",
            "Speed: 1.7ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "⏹ Segmentation stopped.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aef5a1981996467c8baebbc771aa8a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "jpeg",
            "height": "",
            "layout": "IPY_MODEL_87ea9e966d5549aaa050d7702fe355cb",
            "width": ""
          }
        },
        "87ea9e966d5549aaa050d7702fe355cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}